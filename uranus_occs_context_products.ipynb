{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c018e62b",
   "metadata": {},
   "source": [
    "### Using lxml parser for Matt's uranus_occs_obs_syst_to_spreadsheet.py script:\n",
    "\n",
    "Note: I've called Matt's output `uranus_occs_info_auto.csv` as `uranus_occs_info_auto_matt.csv` (which I use to check my code works below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287eebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup # Import BeautifulSoup4 (not BeautifulSoup3)\n",
    "from astropy.table import Table\n",
    "import os\n",
    "\n",
    "infile = 'obs_syst-templates-2021-03-22a_matt.txt'\n",
    "outfile = 'uranus_occs_info_auto_mia.csv'\n",
    "\n",
    "# Check input file exists\n",
    "if os.path.isfile(infile):\n",
    "    print( 'Found source file: ', infile )\n",
    "else:\n",
    "    print( infile, 'not found!' )\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Read the XML file\n",
    "with open(infile, \"r\") as fin:\n",
    "    # Read each line in the file, readlines() returns a list of lines\n",
    "    content = fin.readlines()\n",
    "    # Combine the lines in the list into a string\n",
    "    bsoup_content = bsoup(\"\".join(content), \"lxml\") #pass the content into the BeautifulSoup library as well as the lxml parser \n",
    "\n",
    "# Initialise lists for storage purposes:\n",
    "facility_names = []; telescope_names = []; instrument_names = []\n",
    "facility_lids = []; telescope_lids = []; instrument_lids = []\n",
    "\n",
    "for obsyscomp in bsoup_content.find_all('observing_system_component'):\n",
    "    for obsyscomptype in obsyscomp.find(\"type\"):\n",
    "        if obsyscomptype == \"Host\" and obsyscomp.parent.find('name').text != \"Hubble Space Telescope FOS\" : # Gotcha: The HST does not have a <type>=\"Telescope\" (only \"Host\" and \"Instrument\")\n",
    "            facility_name = (obsyscomp.find(\"name\").text)\n",
    "            facility_lid = obsyscomp.find(\"lid_reference\").text\n",
    "            facility_names.append(facility_name)\n",
    "            facility_lids.append(facility_lid)\n",
    "        elif obsyscomptype == \"Telescope\" and obsyscomp.parent.find('name').text != \"Hubble Space Telescope FOS\" : \n",
    "            #print(\"here:\", obsyscomp.parent.text)\n",
    "            telescope_name = (obsyscomp.find(\"name\").text)\n",
    "            telescope_lid = obsyscomp.find(\"lid_reference\").text\n",
    "            telescope_names.append(telescope_name)\n",
    "            telescope_lids.append(telescope_lid)\n",
    "        elif obsyscomptype == \"Instrument\" and obsyscomp.parent.find('name').text != \"Hubble Space Telescope FOS\":\n",
    "            instrument_name = (obsyscomp.find(\"name\").text)\n",
    "            instrument_lid = obsyscomp.find(\"lid_reference\").text\n",
    "            instrument_names.append(instrument_name)\n",
    "            instrument_lids.append(instrument_lid)\n",
    "        else:\n",
    "            print(\"Hubble Space Telescope has no type = Instrument, therefore skipping\")\n",
    "\n",
    "table = Table({'facility_lid': facility_lids, \n",
    "               'telescope_lid': telescope_lids,\n",
    "               'instrument_lid': instrument_lids,\n",
    "               'facility_name': facility_names, \n",
    "               'telescope_name': telescope_names,\n",
    "              'instrument_name': instrument_names},\n",
    "              names=('facility_lid', 'telescope_lid', 'instrument_lid', 'facility_name', 'telescope_name', 'instrument_name'))\n",
    "\n",
    "table.write('uranus_occs_info_auto_mia.csv', format='ascii', delimiter=\",\", overwrite=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724136f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff ./uranus_occs_info_auto_matt.csv ./uranus_occs_info_auto_mia.csv # The only difference is that I gave each column a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using lxml parser for Matt's `uranus_occs_create_facility_conprods.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up lxml parser\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "namespace = {'ns':'http://pds.nasa.gov/pds4/pds/v1'}\n",
    "\n",
    "# Define name of input files and make sure they exist, then initialize\n",
    "infofile = './uranus_occs_info_facilities.csv'\n",
    "templatefile = './observatory.template.nohash.xml'\n",
    "\n",
    "for file in [infofile,templatefile]:\n",
    "    if os.path.isfile(file):\n",
    "        print( 'Found source file: ', file )\n",
    "    else:\n",
    "        print( file, 'not found!' )\n",
    "        sys.exit(1)\n",
    "        \n",
    "with open( infofile, 'r' ) as info:\n",
    "    infolines = info.readlines()\n",
    "\n",
    "# Get field tags from the first line of infofile\n",
    "infotags = infolines[0].split(',')\n",
    "# The first column does not have (or need) a well-behaved tag, but do this\n",
    "#   so that everything works easily\n",
    "infotags[0] = 'create_conprod'\n",
    "\n",
    "# Remove leading and trailing $ in tag names\n",
    "for i in range(len(infotags)):\n",
    "    infotags[i] = infotags[i].strip(\"$,\\n\") #trim off prefix/suffix \"$\"s and the concluding CR\n",
    "    \n",
    "for i,infoline in enumerate(infolines):\n",
    "    if infoline.startswith('1'): # I'm guessing this is a switch (flag) that Matt has manually put in to designate whether that record has enough infor to warrant output file being written?\n",
    "        infofields = infoline.split(',') # splits the row-string into a list where each word is an element\n",
    "        infofields[-1] = infofields[-1].rstrip(\"\\n\")   # Remove the concluding CR\n",
    "        infodict = dict(zip( infotags, infofields )) # Create a dictionary where the names and corresponding values are zipped into a dictionary of (header, value) pairs\n",
    "        outfile = 'outputs_lxml/'+infofields[1].rsplit(':')[-1]+'_1.0.xml' # Use the unique name from the facility URN to name the output file        \n",
    "        # Define name of output file and make sure we don't overwrite anything,\n",
    "        #   then initialize\n",
    "        if os.path.isfile(outfile):\n",
    "            print( outfile, 'already exists!' )\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            print( 'Writing to', outfile )\n",
    "  \n",
    "        # Parse the template file\n",
    "        tree = etree.parse(templatefile, parser)        \n",
    "        # Find the placeholders and replace with desired values from infodict:\n",
    "        tree.find(\"//ns:logical_identifier\", namespaces=namespace).text =  infodict['facility_lid']\n",
    "        tree.find(\"//ns:title\", namespaces=namespace).text =  infodict['facility_title']\n",
    "          \n",
    "        for i, alt_id in enumerate(tree.findall(\"//ns:alternate_id\", namespaces=namespace), start=1):\n",
    "            alt_id.text = infodict['alternate_id'+str(i)]\n",
    "            #Remove all unpopulated tags\n",
    "            if not infodict['alternate_id'+str(i)]: #if field is empty\n",
    "                alt_id.getparent().remove(alt_id)# delete empty element\n",
    "\n",
    "        for i, alt_title in enumerate(tree.findall(\"//ns:alternate_title\", namespaces=namespace), start=1):\n",
    "            alt_title.text = infodict['alternate_title'+str(i)]\n",
    "            #Remove all unpopulated tags\n",
    "            if not infodict['alternate_title'+str(i)]: #if field is empty\n",
    "                alt_title.getparent().remove(alt_title)# delete empty element\n",
    "        \n",
    "        tree.find(\"//ns:modification_date\", namespaces=namespace).text = datetime.today().strftime('%Y-%m-%d')\n",
    "        \n",
    "        for i, lid_ref in enumerate(tree.findall(\"//ns:lid_reference\", namespaces=namespace), start=1):\n",
    "            lid_ref.text = infodict['telescope_lid'+str(i)]\n",
    "            #Remove all unpopulated tags\n",
    "            if not infodict['telescope_lid'+str(i)]: # if field is empty\n",
    "                (lid_ref.getparent()).getparent().remove(lid_ref.getparent())# delete empty element AND corresponding <reference_type>.... There must be a neater way than accessing the grandparent?!\n",
    "                \n",
    "        tree.find(\"//ns:name\", namespaces=namespace).text = infodict['facility_title']\n",
    "        tree.find(\"//ns:country\", namespaces=namespace).text = infodict['facility_country']\n",
    "        \n",
    "        # Save output to file\n",
    "        tree.write(outfile, encoding='utf8', pretty_print=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5f302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
